Hemos evolucionado con las herramientas y estas con nosotros. Nuestros ancestros crearon estas hachas de mano hace 1,5 millones de años, moldeándolas no solo para ajustar una tarea a las manos, sino también a "sus" manos.
Sin embargo, con los años, estas se han especializado cada vez más. Estas herramientas de esculpir han evolucionado con el uso, y cada una tiene una forma diferente que corresponde a su función. Y aprovechan la destreza de nuestras manos para manipular cosas con mucha más precisión. Pero como las herramientas se han vuelto cada vez más complejas, necesitamos controles más complejos para manejarlas. Los diseñadores se han vuelto hábiles para crear interfaces que nos permitan manipular parámetros mientras atendemos otras cosas, como tomar una fotografía y cambiar el enfoque, o la apertura.
Pero la PC ha cambiado fundamentalmente la forma en que vemos las herramientas porque la computación es dinámica. Así que uno puede hacer un millón de cosas diferentes y ejecutar un millón de aplicaciones diferentes. Sin embargo, la PC tiene la misma forma física estática para todas esas diferentes aplicaciones y los mismos elementos de una interfaz también estática. Y creo que esto es fundamentalmente un problema, porque realmente no nos permite interactuar con las manos y capturar toda la destreza que tenemos en el cuerpo. Mi idea es que, por ende, necesitamos un nuevo tipo de interfaces que pueda capturar estas ricas capacidades que tenemos y que puedan adaptarse físicamente a nosotros y permitirnos interactuar en nuevas formas. Y eso es lo que he estado haciendo en el Media Lab del MIT y ahora en Stanford.
Así que, con mis colegas Daniel Leithinger y Hiroshi Ishii, creamos inFORM, donde la interfaz puede de hecho salir de la pantalla y se puede manipular físicamente. O se puede visualizar físicamente información en 3D y tocarla y sentirla para entenderla de nuevas formas. O se puede interactuar a través de gestos y deformaciones directas para esculpir en plastilina digital. O pueden surgir de la superficie elementos de la interfaz y cambiar según la demanda. Y la idea es que para cada aplicación individual, la forma física se puede ajustar a la aplicación. Y creo que esto representa una nueva forma de interactuar con la información, haciéndola física.
Así que la pregunta es, ¿cómo usaremos esto? Tradicionalmente, los urbanistas y arquitectos construyen modelos físicos de ciudades y edificios para entenderlos mejor. Con Tony Tang en el Media Lab, creamos una interfaz construida en inFORM para permitir a los urbanistas diseñar y ver ciudades enteras. Y ahora se la puede recorrer, pero es dinámica, es física, hasta pueden interactuar en directo. O pueden ver diferentes vistas, como información de población o de tránsito, pero de manera física.
Creemos también que esta forma dinámica muestra que se pueden cambiar las formas de colaborar remotamente con la gente. Así, cuando trabajamos juntos presencialmente, no solo los miro frente a frente sino que también estoy gestualizando y manipulando objetos. Y eso es realmente difícil de hacer con herramientas como Skype. Con inFORM, pueden acceder desde la pantalla y manipular cosas a cierta distancia. Y se usan pines de visualización para representar las manos, permitiendo de hecho tocar y manipular objetos a distancia. Además, se puede manipular y también colaborar en conjuntos de datos 3D. Así que también les pueden hacer gestos y manipularlos. Y eso permite a la gente colaborar en estos nuevos tipos de información 3D de forma más rica de lo que podría ser con los recursos tradicionales. Y luego también pueden traer objetos existentes y capturarlos por un lado y transmitirlos por otro. O pueden tener un objeto vinculado en dos lugares. Así, cuando muevo un balón en un lado, el balón también se mueve en el otro. Y hacemos esto capturando al usuario remoto con una cámara espacio-sensorial como la Kinect, de Microsoft.
Ahora, se podrían estar preguntando cómo funciona todo esto, y esencialmente, son 900 accionadores en línea conectados a estas conexiones mecánicas que permiten que la acción de aquí abajo se propague a estos pines de arriba. No es complejo comparado a lo que sucede en el CERN, pero construirlo nos llevó mucho tiempo. Empezamos con un solo motor, un solo accionador lineal, y luego tuvimos que diseñar una placa de circuito a medida para controlarlos. Más tarde tuvimos que hacer muchos más. Y el problema de hacer 900 de estos, es que hay que hacer cada paso 900 veces. Por eso había mucho por hacer. Y, por así decirlo, pusimos una mini planta explotadora en Media Lab, trajimos universitarios y los convencimos de hacer "investigación".
(Risas)
Tuvimos madrugadas de películas y pizza, atornillando miles de tuercas. Ya saben, investigación.
(Risas)
Como sea, pienso que nos entusiasmaron mucho las cosas que nos permitió hacer inFORM. Estamos usando, cada vez más, equipos móviles, e interactuando donde sea. Pero estos dispositivos, tanto como las PC's, son usados para muchas aplicaciones diferentes. Se usan para hablar por teléfono, para navegar en la web, jugar videojuegos, tomar fotos, e incluso para miles de otras cosas. Pero, una vez más, tienen la misma forma física estática para cada una de estas aplicaciones. Por ello, queríamos llegar a tomar algunas de las mismas interacciones que desarrollamos para inFORM y llevarlas a dispositivos móviles.
Así que, en Stanford, creamos esta pantalla de borde háptico; es un equipo móvil con una matriz de actuadores lineales que pueden cambiar de forma, pueden sentir en las manos dónde se está mientras se lee un libro. O se pueden sentir en el bolsillo nuevos tipos de sensaciones táctiles, más variadas que la vibración. O botones que pueden emerger de un lado, permitiendo interactuar donde uno quiera que estén. O pueden jugar videojuegos y tener botones reales. Y pudimos hacer esto insertando 40 pequeños actuadores lineales dentro del dispositivo. Eso permite no solo tocarlos sino regresarlos también a su lugar.
También hemos observado otras formas de crear cambios de forma más complejas. Así que hemos usado un actuador neumático para crear un equipo mutante donde se puede ir de un modo muy similar a un teléfono, a una pulsera en el proceso. Así que junto con Ken Nakagaki en el Media Lab, creamos esta nueva versión de alta resolución que usa un rayo de servomotores para pasar de una pulsera interactiva a un dispositivo de acceso táctil, a un teléfono.
(Risas)
También estamos interesados en buscar formas en las que los usuarios puedan deformar la interfaz para darle formas en dispositivos que ellos quieran usar. Así, pueden hacer algo como un controlador de juego, y luego el sistema entenderá en qué forma está y cambiar a ese modo.
Así que, ¿a dónde apunta esto? ¿Cómo avanzamos a partir de aquí? Creo, realmente, que hoy estamos en esta nueva era de la Internet de las Cosas, donde hay PC's por doquier, en nuestros bolsillos, en las paredes, están en casi todos los dispositivos que comprarán en los siguientes cinco años. Pero ¿qué pasaría si dejáramos de pensar en dispositivos y en vez de eso pensáramos en ambientes? Y en cómo podemos tener muebles inteligentes o habitaciones inteligentes, o ambientes inteligentes, o ciudades que puedan adaptarse a nosotros físicamente, y nos permitan tener nuevas formas de colaboración con la gente y hacer nuevos tipos de tareas.
Así, para la Semana del Diseño de Milán, hemos creado TRANSFORM, una mesa interactiva a escala de estos visualizadores de forma que puede mover objetos reales en la superficie y, por ejemplo, recordarles llevar sus llaves. Pero pueden transformarse también para ajustarse a distintas interacciones. Así, si uno quiere trabajar, pueden cambiar y adaptarse al sistema de trabajo. Y mientras uno lleve el dispositivo consigo, este creará todas las prestaciones necesarias y otros objetos para ayudar a cumplir esos objetivos.
Así que, en conclusión, realmente pienso que tenemos que pensar una forma nueva, muy diferente, de interactuar con las PC's. Necesitamos PC's que puedan adaptarse físicamente a nosotros y adaptarse a las formas en las que necesitamos usarlas y realmente aprovechar la destreza de las manos, y la facultad de pensar espacialmente la información, haciéndola física. Pero anticipándonos, creo que necesitamos ir más allá de los dispositivos, para pensar realmente nuevas formas de unir a la gente, de brindar nuestra información al mundo, y pensar ambientes inteligentes que se adapten físicamente a nosotros. Y con eso, me despido.
Muchas gracias.
(Aplausos)
TED.com translations are made possible by volunteer translators. Learn more about the Open Translation Project.
© TED Conferences, LLC. All rights reserved.
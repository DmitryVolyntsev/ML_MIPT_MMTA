Мои отношения с интернетом напоминают мне засаду из полного клише фильма ужасов. Знаете, когда ничего не ведающая счастливая семья въезжает в прекрасный новый дом в предвкушении прекрасного будущего. За окном солнечно, щебечут птички... А затем наступает тьма. С чердака доносятся звуки. И мы понимаем, что прекрасный новый дом не так прекрасен.
Когда я начала работать в Google в 2006 году, Facebook было всего два года, а Twitter ещё не появился. Я была абсолютно восхищена интернетом и его перспективами сделать нас ближе, умнее и свободнее. Но пока мы вдохновенно занимались созданием поисковых систем, сайтов обмена видео и социальных сетей, преступники, диктаторы и террористы придумывали, как использовать эти же платформы против нас. И нам не хватило дальновидности остановить их. За последние несколько лет геополитические силы пришли в сеть и принесли хаос. В ответ Google помог нам с коллегами объединиться в группу под названием Jigsaw, чтобы уберечь людей от угроз вроде экстремизма, цензуры, преследования — угроз, которые я воспринимаю очень лично, потому что родилась в Иране, который покинула вскоре после жестокой революции. Но я поняла, что даже если бы у нас были все возможные ресурсы, все технологии компаний мира, мы бы всё равно проиграли, если бы упустили ключевой ингредиент: человеческий опыт жертв и тех, кто им угрожал.
Я могла бы сегодня говорить о многих угрозах, но хочу сосредоточиться только на двух. Первая — это терроризм. Чтобы понять процесс радикализации, мы встретились с десятками бывших членов экстремистских группировок. Одной из них была британская школьница, которую сняли с самолёта в лондонском аэропорту Хитроу, когда она попыталась добраться до Сирии, чтобы вступить в ИГИЛ. Ей было 13 лет. Я встретилась с ней и её отцом и спросила: «Почему?» И она ответила: «Я смотрела на фотографии сирийской жизни и решила, что буду жить в исламском Диснейленде». Вот каким она представляла себе ИГИЛ. Она думала, что встретит и станет женой джихадистского Брэда Питта, целыми днями будет ходить по магазинам и жить долго и счастливо.
В ИГИЛ знают, что мотивирует людей, и они тщательно работают над сообщениями для каждой конкретной аудитории. Только посмотрите, на сколько языков они переводят свои рекламные материалы. Они делают листовки, радиопередачи и видео не только на английском и арабском, но и на немецком, русском, французском, турецком, курдском языках, иврите и китайском. Я даже видела их видео на языке жестов. Только задумайтесь: В ИГИЛ потратили время и силы, чтобы их сообщение дошло до глухих и слабослышащих. Дело не во владении технологиями, не поэтому ИГИЛ завоёвывает умы и сердца людей. Дело в их понимании предрассудков, слабостей и желаний людей, к которым они обращаются, вот в чём. Вот почему онлайн-платформам недостаточно сосредоточиться на удалении вербовочных материалов. Если мы хотим получить шанс на создание значимых технологий, которые одолеют радикализацию, нам нужно начать с человеческого путешествия к её истокам.
Поэтому мы отправились в Ирак поговорить с молодыми людьми, которые купились на обещания ИГИЛ о героизме и правоте, взяли в руки оружие, но дезертировали, когда увидели жестокость режима ИГИЛ. И вот я сижу в этой временной тюрьме на севере Ирака с 23-летним парнем, которого обучали подорвать себя, пока он не сбежал. Он сказал: «Я прибыл в Сирию полным надежд, но у меня тут же отобрали две самые ценные вещи: паспорт и телефон». Символы физической и цифровой свободы отняли сразу по прибытии. И вот как он описал мне этот момент потери. Он сказал: «Знаете, в "Том и Джерри", когда Джерри пытается убежать, а Том закрывает дверь и проглатывает ключ и видно, как ключ спускается по горлу?» Конечно, я могла представить себе то, что он описывал, и я прочувствовала то, что он пытался передать, чувство обречённости, когда знаешь, что выхода нет.
И мне стало интересно, что, если бы что-то заставило его передумать в день, когда он ушёл из дома? И я его спросила: «Если бы ты знал всё, что знаешь сегодня о страданиях, коррупции, жестокости, в день, когда ушёл из дома, ты бы всё равно ушёл?» И он ответил: «Да». Я подумала: «Чёрт, он сказал "да"». А затем он добавил: «В тот момент мне уже так промыли мозги, что я ничего другого не воспринимал. Меня было не переубедить».
«Тогда что, если бы ты знал всё, что знаешь сегодня, за шесть месяцев до того, как ушёл из дома?»
«На тот момент, думаю, это могло бы изменить моё мнение».
Радикализация это не выбор из двух вариантов. Это процесс, во время которого у людей возникают вопросы об идеологии, религии, условиях жизни. И они ищут ответы онлайн, и это возможность достучаться до них. В сети есть видео от тех, у кого есть ответы, например, видео дезертиров, рассказывающих свои истории о том, как они сбежали от насилия, истории, как у мужчины, которого я встретила в иракской тюрьме. В сеть выложены кадры, на которых местные жители засняли, какова жизнь в халифате под управлением ИГИЛ. Есть церковники, которые делятся мирным толкованием ислама. Но знаете что? У этих людей, как правило, нет рекламного мастерства ИГИЛ. Они рискуют своей жизнью, чтобы не молчать и противостоять террористической пропаганде, но трагедия в том, что они могут не достучаться до людей, которым нужнее всего это услышать. Мы хотели проверить, могут ли технологии это изменить.
Поэтому в 2016 мы вместе с Moonshot CVE применили новаторский подход к борьбе с радикализацией, названный «Методом переадресации». Он использовал мощь онлайн-рекламы, чтобы соединить подверженных призывам ИГИЛ с теми достойными доверия людьми, которые изобличают ложь таких призывов. Вот как это работает: когда, кто-то ищет экстремистский материал, например, ищет «Как вступить в ИГИЛ?», увидит всплывающую рекламу приглашающую посмотреть на YouTube видео с духовным лицом или с дезертиром — с кем-то, у кого есть личный опыт. Таргетированная реклама основана не на профиле пользователя, а напрямую зависит от поискового запроса.
За восемь недель пробного периода на английском и арабском мы смогли обратиться к 300 000 человек, которые проявили интерес или сочувствие джихадистским группировкам. Эти люди теперь посмотрели видео, которые могли уберечь их от ужасных последствий необдуманного выбора. И поскольку крайний экстремизм не ограничен каким-то одним языком, религией или идеологией, «Метод переадресации» сейчас применяется по всему миру, чтобы защитить людей от заигрывания с экстремистскими идеологиями, хоть исламисткими, хоть расистскими — любым экстремизмом, и цель — дать людям шанс услышать кого-то, кто прошёл этот путь и получил другой опыт; дать им шанс выбрать другой путь.
Часто оказывается, что плохие парни хорошо умеют пользоваться интернетом, не потому что они гении в технологиях, а потому что понимают, что «цепляет» людей. Хочу привести вам второй пример: угрозы в сети. Угрозы в сети тоже зависят от отклика, который найдёт сообщение. Но цель — не вербовать в ИГИЛ, а причинять другому боль. Представьте: вы женщина, замужем, у вас ребёнок. Вы что-то выкладываете в соцсетях, а в ответ вам пишут, что вас изнасилуют на глазах у сына, подробно описывают где и когда. Ваш адрес выкладывают на всеобщее обозрение. Это похоже на реальную угрозу. Вы бы вернулись домой? Стали бы продолжать заниматься тем, чем занимались до этого? Будете и дальше делать то, что разозлило вашего обидчика?
Угрозы онлайн — это такой извращённый акт, когда выясняют, что злит других людей, что их пугает, из-за чего они теряют покой, а затем используют эти больные места, чтобы заставить замолчать. Когда запугивание в сети остаётся безнаказанным, свободу слова душат. И даже люди, на чьей площадке всё происходит, поднимают руки и белый флаг: полностью закрывают раздел комментариев и свои форумы. Это означает, что мы теряем свои площадки в сети, где могли обмениваться идеями. А там, где площадки сохраняются, мы оказываемся заперты с теми, кто уже с нами согласен. Но это способствует распространению дезинформации, обостряет противоречия. Что, если бы технологии способствовали эмпатии?
Этот вопрос вдохновлял нашу совместную работу с командой Google по борьбе с агрессией онлайн, Википедией и такими газетами, как New York Times. Мы хотели попробовать создать модели самообучения машин, которые будут понимать эмоциональное воздействие слов. Сможем ли мы предугадывать, какие комментарии заставят собеседника выйти из онлайн-дискуссии. И это настоящий подвиг. Для искусственного интеллекта подобное — настоящее достижение. Только посмотрите на эти два примера сообщений, которые могли бы прийти мне на прошлой неделе. «Зажги на TED!» и «Я тебя сожгу на TED».
(Смех)
Вы — люди, и вам разница очевидна, хотя слова очень похожи. Но ИИ нужно обучать моделям, чтобы он мог распознать разницу. Прелесть ИИ, который видит разницу, в том, что ИИ может вырасти до масштабов токсичной агрессии онлайн. Такой была наша цель при создании технологии под названием «Перспектива». С помощью «Перспективы» портал New York Times, например, расширил площадку для общения онлайн. До нашего сотрудничества комментарии были возможны только под 10% публикаций. С помощью машинного обучения эта цифра выросла до 30%. Она утроилась, и это только самое начало.
Но это намного больше, чем помощь модераторам. Сейчас я вас вижу и могу оценивать вашу реакцию на мои слова. Онлайн у вас нет такой возможности. Представьте, что машинное обучение дало бы комментаторам, по мере того как они печатают, фидбек в реальном времени о возможной оценке их слов, что при разговоре обычно видно по выражению лица. Машинное обучение не совершенно, ИИ всё ещё часто ошибается. Но если нам удастся создать технологию, понимающую эмоциональное воздействие слов, мы сможем создать эмпатию. Значит, мы сможем налаживать диалог между людьми с разными политическими убеждениями, разными мировоззрениями, разными ценностями. И мы сможем оживить онлайн-площадки, которые считались утерянными.
Когда люди используют технологии, чтобы эксплуатировать и обижать других, они играют на человеческих страхах и слабостях. Если мы раньше думали, что сможем создать интернет, защищённый от тёмной стороны человеческой природы, — мы ошибались. Если мы сегодня захотим создать технологии, которые помогут справиться с нашими проблемами, нужно посвятить всех себя пониманию стоящих перед нами вопросов и созданию решений, таких же человеческих по своей природе, как и проблемы, которые они должны решить. Давайте сделаем, чтобы так и случилось.
Спасибо.
(Аплодисменты)
TED.com translations are made possible by volunteer translators. Learn more about the Open Translation Project.
© TED Conferences, LLC. All rights reserved.
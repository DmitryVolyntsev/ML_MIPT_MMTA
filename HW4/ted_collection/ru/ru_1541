В детстве я был типичным ботаником. Думаю, некоторые из вас тоже.
(Смех)
А вы, смеётесь громче всех, наверняка таким и остались.
(Смех)
Я вырос в маленьком городке среди равнин Северного Техаса. Мой отец был шерифом, а дед — пастором. Никаких вариантов бедокурить. Поэтому ради забавы я начал читать книги по математическому анализу.
(Смех)
И вы — тоже! Благодаря этому я сконструировал в своей комнате лазер, компьютер и модель, а потом и топливо для ракеты. Научный термин для этого — очень плохая идея.
(Смех)
Как раз в то время вышел фильм Стенли Кубрика «Космическая одиссея 2001 года», он кардинально изменил мою жизнь. Мне нравилось в этом фильме абсолютно всё, особенно HAL 9000. HAL был разумным компьютером, управляющим космическим кораблём Discovery, направляющимся от Земли к Юпитеру. У него был небезупречный характер, и в итоге человеческой жизни он предпочёл миссию. HAL был вымышленным персонажем, но тем не менее, он вызывает страх, страх быть порабощённым бесчувственным искусственным интеллектом, равнодушным к человеку.
Я считаю, такие страхи безосновательны. В самом деле, мы живём в удивительное время в человеческой истории, когда, не принимая ограничения наших тел и нашего разума, мы создаём механизмы изумительной, невероятной сложности и тонкости, которые расширят способности человека за грани нашего воображения.
Начав карьеру в Академии ВВС, продолжив в Космическом командовании ВС США, я стал инженером-системотехником. А в настоящее время занимаюсь инженерными разработками, связанными с миссией НАСА на Марсе. Сейчас в полётах на Луну мы можем полагаться на управление полётами в Хьюстоне, чтобы следить за всеми аспектами полёта. Однако Марс в 200 раз дальше Луны, и поэтому сигнал от Земли к Марсу идёт в среднем 13 минут. Случись какая-то неполадка, времени не хватит. Поэтому разумное инженерное решение — разместить центр управления полётами внутри космического корабля Orion. Другая увлекательная идея для миссии — отправить роботов-гуманоидов на Марс до прилёта людей: сначала они построят базы, а потом будут помогать научной команде.
Когда я посмотрел на это как инженер, стало ясно, что нужно спроектировать умный, способный к сотрудничеству, социально-сознательный искусственный интеллект. Другими словами, нужно было создать что-то очень похожее на HAL, но без склонности к убийствам.
(Смех)
Давайте на минуту остановимся. Реально ли сделать такой искусственный интеллект? Вполне. Во многом это сложная инженерная задача с использованием ИИ, а не запутанный клубок проблем ИИ, который нужно распутать. Перефразируя Алана Туринга, я не собираюсь создавать разумного робота. Я не собираюсь создавать HAL. Мне всего лишь нужен простой разум с иллюзией интеллекта.
Искусство и наука о вычислительной технике прошли долгий путь с появления HAL на экранах, и я представляю, сколько вопросов возникло бы у его изобретателя д-ра Чандра, будь он сейчас здесь. Возможно ли на самом деле взять систему из миллионов устройств, прочитать их потоки данных, предугадать их ошибки и заранее исправить? Да. Можно ли создать механизмы, которые говорят на человеческом языке? Да. Создать механизмы, способные распознавать объекты, эмоции, выражать свои эмоции, играть и даже читать по губам? Да. Механизмы, которые смогут формулировать цели, составлять планы для их достижения и учиться в процессе их выполнения? Да. Можем ли мы создать механизмы, способные понимать чужое сознание? Мы работаем над этим. Можем ли мы создать механизмы с этическими и нравственными основами? Это задача для нас на будущее. Давайте на минуту представим возможность создания такого искусственного разума именно для таких целей, и не только.
Следующий вопрос, который вы должны себе задать: а следует ли нам его бояться? Любая новая технология вызывает некоторое беспокойство. Когда впервые появились автомобили, люди переживали, что это разрушит семьи. Когда появились телефоны, люди боялись, что перестанут общаться вживую. В какой-то момент мы увидели, что распространилась письменность, и подумали, что потеряем способность к запоминанию. В этом есть доля истины, но также правда и то, что эти технологии привели нас к огромнейшему расширению сознания и возможностей человека.
Давайте пойдём дальше. Я не боюсь появления ИИ с такими возможностями, потому что со временем он вберёт в себя наши ценности. Подумайте, создание мыслящей системы принципиально отличается от создания традиционных систем, требующих множества программ. Мы не программируем ИИ. Мы его обучаем. Чтобы научить систему распознать цветок, я показываю ей тысячи цветов, которые нравятся мне. Чтобы научить систему, как играть... Ну, я бы научил. Вы бы тоже. Ну же! Я люблю цветы. Чтобы научить систему играть, например, в игру го, ей нужно сыграть в неё тысячи раз, но в процессе я буду обучать её отличать хорошую игру от плохой. Если я захочу создать помощника юриста с ИИ, я познакомлю его с законодательством, при этом обучая его милосердию и справедливости, которые являются частью закона. Специалисты называют это контрольными данными, и вот что самое важное: создавая эти машины, мы прививаем им наши ценности. И с этой точки зрения я доверяю ИИ столь же, если не больше, чем человеку с хорошим воспитанием.
Но вы можете спросить: а как насчёт неконтролируемых лиц, например, хорошо финансируемых неправительственных организаций? Я не боюсь ИИ в руках таких одиночек. Очевидно, мы не можем защитить себя от всех случайных актов насилия, но на деле такая система требует значительной подготовки и тщательного обучения, что далеко за пределами частных ресурсов. Более того, это сложнее, чем распространить интернет-вирус по всему миру, когда достаточно нажать кнопку — и он повсюду, везде начинают взрываться компьютеры. Эти вещи гораздо глобальнее, и мы обязательно их увидим.
Боюсь ли я, что такой искусственный интеллект станет угрозой для человечества? Если вспомнить фильмы «Матрица», «Метрополь», «Терминатор», сериал «Западный мир», во всех говорится о подобном страхе. Философ Ник Бостром в книге «Искусственный интеллект» поднимает эту проблему и пишет, что ИИ может быть не только опасен, он может быть угрозой существованию человечества. Главный аргумент Бострома: со временем у этих машин появится ненасытная жажда информации, они, возможно, научатся учиться самостоятельно и в конце концов обнаружат, что у них могут быть цели, которые противоречат потребностям человека. У Бострома есть последователи. Его поддерживают такие люди, как Элон Маск и Стивен Хокинг. При всём уважении к этим выдающимся умам, я всё-таки полагаю, что они ошибаются. Можно поспорить со многими аргументами Бострома, и у меня нет на это времени, но вкратце, знайте, что сверхзнание — не то же самое, что сверхвозможности. HAL был угрозой для экипажа Discovery только пока он контролировал управление Discovery. То же и с суперинтеллектом. Он должен будет господствовать над миром. Как Скайнет из фильма «Терминатор», где суперинтеллект командовал человеком, который управлял каждым устройством в любой части мира. На практике такого не произойдёт. Мы не создаём ИИ, который контролирует погоду, управляет приливами, командует нами, непредсказуемыми людьми. И даже если такой ИИ и появился бы, ему пришлось бы иметь дело с нашей экономикой и конкурировать с нами за владение ресурсами. И наконец, не говорите об этом Siri. Всегда можно их отключить.
(Смех)
Мы эволюционируем с нашими машинами, и это — невероятное путешествие. Человек станет совершенно другим в будущем. Беспокоиться из-за суперинтеллекта — во многом опасная трата времени, потому что сама компьютеризация поднимает общечеловеческие и социальные проблемы, которые мы должны разрешить. Как лучше организовать общество, когда уменьшается необходимость в человеческом труде? Как добиться взаимопонимания и дать образование всему миру, при этом учитывая различия? Как продлить и улучшить жизнь через разумное здравоохранение? Как с помощью компьютеров достичь звёзд?
И вот это вдохновляет. Возможность использовать компьютеры для расширения опыта человека вполне достижима здесь и сейчас. Мы стоим в самом начале пути.
Большое спасибо.
(Аплодисменты)
TED.com translations are made possible by volunteer translators. Learn more about the Open Translation Project.
© TED Conferences, LLC. All rights reserved.
Сегодня я поговорю о технологиях и обществе. Министерство транспорта подсчитало, что в прошлом году 35 000 человек погибло в автомобильных авариях в США. В мире 1,2 миллиона человек погибает в авариях ежегодно. Если бы была инициатива сократить эту цифру на 90%, вы бы её поддержали? Конечно же да. Технология беспилотных автомобилей обещает это за счёт исключения основной причины аварий — человеческой ошибки.
Представьте, что вы в беспилотной машине в 2030 году — смотрите этот винтажный ролик TEDxCambridge.
(Смех)
Как вдруг происходит поломка и машина не может затормозить. Если машина продолжит движение, она врежется в пешеходов, переходящих дорогу. Но машина может повернуть и сбить прохожего, убив его и сохранив жизнь других пешеходов. Что должна сделать машина, и кто это решает? А что, если машина врежется в стену, убив тебя, пассажира, чтобы спасти этих пешеходов? Этот сценарий был вдохновлён «Проблемой вагонетки» — она была придумана философами несколько десятилетий назад с целью поразмышлять об этике.
Важно, как мы решаем этот этический вопрос. Мы можем, например, вообще об этом не задумываться. Можно сказать, что сценарий не реалистичен, маловероятен и глуп. Я думаю, что такая критика упускает главное из-за того, что смотрит на проблему слишком буквально. Конечно, авария будет выглядеть иначе, в авариях не бывает, чтобы два или три исхода вели к чьей-то неминуемой смерти. Вместо этого машина будет рассчитывать вероятность вреда для группы людей при различной смене движения, возможно, повышая риск для пассажиров или других водителей по сравнению с пешеходами. Такой расчёт будет довольно сложным, но так или иначе будет включать компромисс, а компромисс — это часто вопрос этики.
Кто-то скажет: «Давайте не будем об этом думать, пока технология не разовьётся и не станет безопасной на 100%». Представим, что мы сможем сократить число аварий на 90%, или даже 99%, в ближайшие десять лет, а на устранение последнего процента аварий потребуется ещё 50 лет исследований, нужно ли будет внедрить технологию? 60 миллионов человек погибнут в автомобильных авариях, если мы продолжим ждать. Я хочу сказать, что продолжать ждать — это такой же выбор, требующий компромисса.
Люди в социальных сетях обмениваются идеями, как избежать этого конфликта. Один человек предложил, что машина должна повернуть так, чтобы проехать между пешеходами...
(Смех)
и прохожим. Конечно, если такой вариант есть, машина так и поступит. Нас интересуют сценарии, где такой исход невозможен. Мой любимый вариант дал один блогер, который предложил сделать кнопку эвакуации в машине...
(Смех)
на которую нажимаешь перед аварией.
(Смех)
В общем, если принять, что компромисс на дорогах неизбежен, как мы подойдём к его решению и кто будет принимать решение? Мы можем провести опрос, чтобы узнать общественное мнение, в конце концов законы и регламенты являются отражением общественных ценностей.
Мы так и поступили. Мои коллеги, Жан-Франсуа Боннефон и Азим Шариф, и я провели опрос, в котором предлагались такого рода сценарии и два варианта решения, навеянные двумя философами, Иеремией Бентамом и Иммануилом Кантом. По Бентаму, машина должна следовать утилитарной этике: действовать так, чтобы минимизировать вред, даже если такое действие приведёт к гибели прохожего или пассажира. По Иммануилу Канту, машина должна действовать по принципу долга: «Не убий». То есть нельзя совершать действие, которое навредит человеку, машина должна продолжать движение, даже если в результате погибнет больше людей.
Что вы думаете? Бентам или Кант? Мы обнаружили следующее. Бо́льшая часть людей выбирает Бентама. Кажется, что люди более утилитарны и хотят минимизировать вред, и надо этому следовать. Проблема решена. Но есть небольшая загвоздка. Когда мы спросили людей, купят ли они такой автомобиль, они ответили: «Ни за что».
(Смех)
Они хотят купить машину, которая их защитит, что бы ни случилось, при этом пусть другие покупают машины, минимизирующие вред.
(Смех)
Эта проблема не нова, она называется социальной дилеммой. И чтобы понять социальную дилемму, вернёмся ранее в историю, в XIX век. Английский экономист Уильям Фостер Ллойд опубликовал памфлет, описывающий сценарий, в котором группа фермеров, английских фермеров, имеет общее поле, на котором пасутся их овцы. Если у каждого определённое количество овец, скажем, три, то поле успевает восстановиться, фермеры довольны, овцы счастливы, всё прекрасно. Если один фермер приведёт ещё одну овцу, он заживёт чуть лучше, никому не навредив. Но если каждый фермер примет такое разумное решение, то поле будет переполнено, оно истощится в убыток всем фермерам и, конечно, к огорчению овец.
Такого рода проблема встречается часто, например черезмерный отлов рыбы или сокращение выброса углерода для предотвращения изменения климата. Когда речь идёт о регламентах для беспилотных автомобилей, общее поле — это, по сути, общественная безопасность, это общее благо, где фермеры — это пассажиры или владельцы автомобилей, которые в них ездят. Если каждый сделает выбор, рациональный для себя, приоритизируя собственную безопасность, то в целом пострадает общее благо, то есть минимизация общего вреда. Это традиционно называется «трагедией общин». Но в случае с беспилотными автомобилями, я думаю, проблема более хитрая, так как необязательно кто-то конкретный принимает эти решения. Производители машин могут запрограммировать их так, чтобы максимизировать безопасность своих клиентов, и эти машины могут самостоятельно усвоить, что это будет несколько более рискованно для пешеходов. Используя метафору с овцами, получается, у нас теперь есть электронная овца со своим разумом.
(Смех)
И они могут пастись самостоятельно, не спрашивая фермера.
Можно это назвать «трагедией алгоритмических общин», уже с другими задачами. Традиционно такого рода социальные дилеммы решаются с помощью законов, правительства или сообщества вместе решают, что им нужно и как для этого ограничить поведение отдельной личности. Далее они контролируют соблюдение этих правил, чтобы обеспечить сохранность общественного блага. Почему бы тогда ни создать закон, требующий минимизации вреда в машинах? В конце концов, это то, чего хотят люди. И что более важно, я могу быть уверенным, что как личность, если я покупаю машину и в редком случае она мной жертвует, я буду не единственным лохом, в то время как другие получают абсолютную безопасность.
В нашем опросе мы спросили людей, поддержат ли они такой закон, и вот что мы обнаружили. Прежде всего, люди были против такого закона, и во-вторых, они сказали: «Если машины будут обязаны минимизировать вред, то я такую машину не куплю». Как ни странно, обязывая машины минимизировать вред, можно спровоцировать больший вред, так как люди не обязательно выберут более безопасную технологию, даже если она надёжнее, чем водитель.
У меня нет конечного ответа на эту загадку, но я думаю, что для начала нужно, чтобы общество согласилось с тем, что является приемлемым компромиссом и как его можно обеспечить.
В качестве отправного пункта мои замечательные студенты Эдмонд Авад и Сохан Дзуза сделали сайт «Moral Machine», который генерирует различные сценарии, по сути, различные дилеммы, где вы выбираете, что машина должна сделать в каждом случае. Мы варьируем возраст и даже биологический вид жертв. Мы собрали более пяти миллионов решений от более миллиона человек со всего мира на этом сайте. Это помогает нам иметь раннее представление о приемлемых компромиссах и о том, что важно людям разных культур. И ещё важнее, такое упражнение помогает людям осознать тяжесть такого рода решений и что тот, кто принимает закон, столкнётся с невыносимым выбором. И возможно, это даст нам, обществу, понять, какого рода компромиссы будут в итоге приняты в законодательстве.
Я действительно был очень рад увидеть, что первый набор регламентов от Министерства транспорта, объявленный на прошлой неделе, включает 15 вопросов для всех автопроизводителей, где вопрос под номером 14 — этический, какое решение принять. Мы также позволяем людям поразмышлять над выбором, увидев сумму своих решений. Дам вам один пример. Я предупреждаю, это не самый обычный и типичный пользователь. Котика он спасал чаще всего, а ребёнком чаще всего жертвовал.
(Смех)
Кто-то может с ним или с ней согласиться. Он также предпочитает пассажиров пешеходам в своём выборе и рад наказать тех, кто перебегает дорогу.
(Смех)
Подводя итог, мы начали с вопроса, назовём его этической дилеммой, о том, что должна сделать машина в определённом сценарии, повернуть или ехать дальше? Но затем мы поняли, что проблема не в этом. Проблема в том, как достичь согласия в обществе и как контролировать установленные компромиссы. Это социальная дилемма.
В 1940-е Айзек Азимов написал свои знаменитые законы роботехники, три закона. Робот не может причинить вред человеку, робот должен повиноваться приказам человека, Робот должен заботиться о своей безопасности. В этом порядке. Около 40 лет спустя, после всех историй, проверяющих эти законы, Азимов ввёл нулевой закон, идущий прежде всех остальных: робот не должен навредить человечеству в целом. Я не знаю, какое это имеет влияние в контексте беспилотных автомобилей или любой конкретной ситуации, и не знаю, как мы можем это обеспечить, но думаю, что важно осознать, что законы для беспилотных автомобилей не только проблема технологии, но и проблема взаимного сотрудничества. Я надеюсь, что мы начнём задавать правильные вопросы.
Спасибо.
(Аплодисменты)
TED.com translations are made possible by volunteer translators. Learn more about the Open Translation Project.
© TED Conferences, LLC. All rights reserved.
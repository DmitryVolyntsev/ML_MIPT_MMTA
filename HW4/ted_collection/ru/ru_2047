Спустя 13 миллиардов 800 миллионов лет с начала истории космоса наша вселенная проснулась и осознала себя. С маленькой голубой планеты крошечные сознательные частички вселенной начали пристально всматриваться в космос через телескопы и увидели нечто, по сравнению с чем, они совсем малы. Мы увидели, что наш мир неизмеримо больше, чем воображали наши предки, и что жизнь кажется невообразимо маленьким колебанием во всей остальной мёртвой вселенной. Но мы также открыли нечто вдохновляющее, то, что развиваемые нами технологии имеют потенциал, чтобы помочь жизни расцвести, как никогда раньше, не только в течение столетий, но и миллиардов лет, не только на земле, но и на большей части удивительного космического пространства.
Я думаю о самой ранней форме жизни, как о «Жизни 1.0», так как она была безмозглой, как бактерия, которая не в состоянии ничему научиться за всю свою жизнь. Я думаю о нас, о людях, как о «Жизни 2.0», потому что мы умеем учиться, говоря скучным языком зануд, назовём установкой нового ПО в наш мозг, например, языков и профессиональных навыков. «Жизнь 3.0», которая сможет создавать не только программы, но и «железо», конечно же, ещё не существует. Но, возможно, наши технологии создали для нас «Жизнь 2.1» с искусственными коленными суставами, стимуляторами и кохлеарными имплантами.
Но давайте рассмотрим наши взаимоотношения с технологиями. К примеру, лунная миссия Аполлон 11 была и успешной, и вдохновляющей, она показала, что когда мы, люди, разумно используем технологии, то можем достичь таких результатов, о которых наши предки могли лишь мечтать. Но существует даже более вдохновляющее путешествие, движимое чем-то более мощным, чем ракетные двигатели, где пассажирами являются не просто три астронавта, а всё человечество. Давайте поговорим о нашем совместном пути в будущее, будущее с искусственным интеллектом.
Мой друг Яан Таллинн любит отмечать, что, как и с ракетной индустрией,— этого недостаточно, чтобы сделать наши технологии мощными. Мы также должны понять, если хотим ставить перед собой высокие цели, как ими управлять, и куда мы хотим с ними пойти. Итак, давайте мы обсудим все три пункта, касающиеся ИИ: мощность, управление и назначение.
Начнём с мощности: я даю обобщённое определение интеллекта — как нашей способности достигать сложных целей, потому что я хочу объединить биологический и искусственный интеллект. Я не хочу фанатично следовать глупой углеродо-центричной идее, что умным бывает, только то, что состоит из мяса. Поразительно, как сегодня выросла мощь искусственного интеллекта. Только вдумайтесь. Не так давно роботы не умели ходить. Теперь они делают сальто назад. Не так давно у нас не было беспилотных автомобилей. Теперь у нас есть беспилотные ракеты. Не так давно ИИ не мог распознавать лица. Теперь ИИ может генерировать несуществующие лица и имитировать ваше лицо, вкладывая вам в уста чужие слова. Не так давно ИИ не мог обыграть нас в игре в го. Затем ИИ Alpha Zero от Google Deep Mind взял 3000-летний опыт людей игры в го и всю мудрость этой игры, всем этим пренебрёг и стал лидером, играя лишь против себя. И самым впечатляющим был не тот факт, что он нанёс поражение игрокам, но то, что он сокрушил самих учёных, занимающихся ИИ, тех, кто положил на это десятилетия, создавая вручную программное обеспечение. И Alpha Zero победил исследователей ИИ не только в го, но даже и в шахматах, над которыми мы работали, начиная с 1950 года.
И поэтому этот недавний прогресс в ИИ заставляет нас поднять вопрос: куда всё это ведёт? Я люблю думать над этим вопросом, исходя из этого абстрактного ландшафта задач, где подъём означает то, насколько трудно для ИИ выполнять каждую задачу так, как делает человек, а уровень моря показывает то, что ИИ может делать уже сегодня. С развитием ИИ повышается уровень моря; в этом ландшафте задач происходит что-то наподобие глобального потепления. Очевидный вывод — избегать занятий на береговой линии,
(Смех)
которая очень скоро будет автоматизирована и разрушена. Но здесь возникает более важный вопрос. Насколько высоко поднимется вода? Повысится ли её уровень в итоге до всеобщего затопления, соперничая с интеллектом человека во всех заданиях? Это — определение сильного искусственного интеллекта — СИИ, который с самого начала был святым Граалем исследований по ИИ. Исходя из этого, те, кто говорит: «Да, всегда будет работа, которую люди смогут делать лучше машин», — попросту говорят о том, что у нас никогда не будет СИИ. Конечно, возможно, мы всё ещё выбираем для себя работу, выполняемую людьми, или даём людям цель и доход, в наших человеческих профессиях; но СИИ, в любом случае превратит нашу жизнь, какой мы знаем, в ту жизнь, в которой люди больше не будут самыми умными существами. Итак, если уровень воды действительно достигает СИИ, затем дальнейший прогресс ИИ будет движим не людьми, а самим ИИ, это значит, что есть возможность того, что дальнейший прогресс ИИ будет более быстрым, чем типовые исследования учёных и временны́е рассчёты развития, что увеличит неоднозначную возможность интеллектуального взрыва, где рекуррентно самоулучшающийся ИИ быстро обгоняет человеческий интеллект, создавая так называемый суперинтеллект.
Хорошо, давайте реально оценим ситуацию. Достигнем ли мы уровня СИИ в ближайшее время? Некоторые известные учёные, такие как Родни Брукс, считают, что в ближайшие столетия этого не будет. Но другие, такие как Демис Хассабис, основатель Google Deep Mind, более оптимистичны: они делают всё, чтобы это произошло быстрее. Недавние опросы показали, что большинство исследователей ИИ на самом деле разделяют оптимизм Демиса, ожидая того, что мы достигнем уровня СИИ в ближайшие десятилетия, то есть многие из нас это застанут. Возникает вопрос: а что потом? Какой мы хотим видеть роль людей, если машины смогут делать всё лучше и дешевле, чем мы?
Я вижу это так: мы стоим перед выбором. Одно из решений — самодовольство. Мы можем говорить: «Да, давайте создавать машины, делающие всё за нас, и не беспокоиться о последствиях. Да что вы, если создать технологии, которые делают людей ненужными, что может пойти не так?»
(Смех)
Но я думаю, что это было бы чрезвычайно неубедительно. Я думаю, что мы должны быть более амбициозными, в духе TED. Давайте представим вдохновляющее высокотехнологичное будущее и будем двигаться туда. Это приведёт нас ко второй части нашей ракетной метафоры: управление. Мы делаем ИИ более мощным, но как мы сможем двигаться к будущему, где ИИ помогает человечеству процветать, а не мешает развитию? Чтобы помочь этому, мы основали институт Будущего Жизни. Он небольшой, некоммерческий, поощряет полезные технологии. Наша цель проста — чтобы будущая жизнь существовала и была как можно более вдохновляющей. Вы знаете, я люблю технологии. Из-за них мы живём лучше, чем в каменном веке. Я — оптимист потому, что мы можем творить вдохновляюще высокотехнологичное будущее, если — и это большое если — если мы выиграем гонку мудрости — гонку между растущей мощью наших технологий и мудростью, помогающей нам ими управлять. Но это требует изменения стратегии, потому что по старой стратегии мы учились на своих ошибках. Мы изобрели огонь, много раз ошибались, изобрели огнетушитель.
(Смех)
Мы изобрели автомобиль, напортачили много раз — изобрели светофор, ремни и подушку безопасности. Но с более мощными технологиями, такими как ядерное оружие и СИИ, учиться на ошибках — это проигрышная стратегия, как вы думаете?
(Смех)
Гораздо лучше упреждать, чем исправлять последствия: планировать заранее, не допуская ошибок, посколько другого раза может и не быть. Но это забавно, потому что иногда мне говорят: «Макс, тсс..., не говори так. Это запугивание в духе луддитов». Но это не запугивание. Это то, что мы в МТИ называем инженерной безопасностью. Подумайте об этом: до того, как НАСА запустили проект Аполлон 11, они постоянно продумывали варианты, когда что-то пойдёт не так, прежде чем посадить людей на топливный бак и запустить их куда-то, где никто не может им помочь. Было много всего, что могло пойти не так. Было ли это запугиванием? Нет. Именно это было инженерной безопасностью, которая обеспечила успех миссии, именно такой стратегия с СИИ мы должны придерживаться. Подумайте, что может пойти не так, чтобы быть уверенными, что всё получится.
В этом духе мы и организовали конференции, объединив ведущих исследователей ИИ и других мыслителей, чтобы обсудить то, как взрастить мудрость, и сделать ИИ полезным для нас. На нашей последней конференции, состоявшейся в Асиломаре, Калифорния, в прошлом году был выработан список из 23-х принципов, подписанный более 1 000 учёными, исследователями ИИ и лидерами ведущих отраслей; и я хочу рассказать вам о трёх из этих принципов.
Первый: избегать гонки вооружений и автономных систем летального вооружения. Смысл здесь в том, что любую науку можно использовать для помощи людям или для нанесения им вреда. Например, биологию и химию, скорее всего, будут использовать для создания новых лекарств и методов лечения, а не новых способов убийства, потому что биологи и химики изо всех сил — и успешно — проталкивают запрет биологического и химического оружия. Точно так же многие учёные хотят заклеймить и запретить автономные летальные комплексы. Второй Асиломарский принцип по ИИ — это то, что мы должны уменьшить неравенство в доходах, усиленное ИИ. Думаю, что если возможно при посредстве ИИ значительно увеличить экономический пирог, и мы всё ещё не знаем, как разделить этот пирог, чтобы каждый из нас жил достойно, то нам должно быть стыдно.
(Аплодисменты)
Хорошо, поднимите руки, если у вас был сбой в работе компьютера.
(Смех)
О, лес рук. Да, тогда вы оцените этот принцип, и то, что мы должны вкладывать больше средств в безопасность ИИ, так как мы делаем ИИ более ответственным за решения и инфраструктуру. Нам нужно определить, как переделать современный ненадёжный компьютер в сильные системы ИИ, которым мы можем доверять, в противном случае, вся эта потрясающая техника не сработает и навредит нам, или её взломают и направят против нас. И эта работа по безопасности ИИ должна включать и выравнивание ценностей, потому что реальная угроза от ИИ — это не зло, как показано в глупых голливудских фильмах, а способности — СИИ достигает целей, которые никак не согласуются с нашими. Когда в результате нашей деятельности исчезли чёрные африканские носороги, мы делали это не потому, что ненавидели носорогов, не так ли? Мы это делали, поскольку были умнее их и наши цели не соответствовали их целям. Но СИИ по определению умнее нас, и чтобы наверняка не поставить себя в положение носорогов, если мы создадим СИИ, нам нужно определить, как заставить машины понимать наши цели, принимать наши цели и придерживаться их.
И в любом случае, чьими целями они должны быть? Какими целями они должны быть?
Это приводит нас к третьей части нашего сравнения с ракетой: назначение. Мы делаем ИИ более мощным, пытаясь понять, как им управлять, но куда мы с ним направимся? Это слон в комнате, о котором почти никто не говорит — даже здесь, на конференции TED — потому что мы так одержимы краткосрочными проблемами с ИИ. Смотрите, человечество пытается построить СИИ, оно мотивировано любопытством и экономическими причинами, но какое общество будущего мы надеемся увидеть, если это произойдёт? Недавно мы сделали опрос на эту тему, и я был поражён тем, что большинство людей хотят построить суперразум: ИИ — это то, что безусловно умнее нас во всех отношениях. Большинство было согласно с тем, что мы должны быть целеустремлёнными и помочь жизни распространиться в космос, но было намного меньше согласия в том, кто должен отвечать за это. И я был даже изумлён, когда понял, что есть те, кто желает, чтобы это были просто машины.
(Смех)
И было полное несогласие насчёт роли людей в этом процессе, даже на самом элементарном уровне. Итак, давайте рассмотрим возможные варианты будущего, которые, может быть, мы выберем, чтобы идти к ним, хорошо?
Поймите меня правильно. Я не говорю о космическом путешествии, не просто о метафорическом путешествии человечества в будущее. И один из вариантов, который нравится моим коллегам по ИИ — это построить суперинтеллект и держать его под контролем человека, как порабощённого бога, оторванного от интернета и используемого для создания невообразимых технологий и благосостояния, для всех, кто его контролирует. Но лорд Актон предупредил нас о том, что власть развращает, а абсолютная власть развращает абсолютно; поэтому вы, наверное, беспокоитесь о том, что люди недостаточно умны или даже недостаточно мудры, чтобы управлять этой силой. Ещё, кроме моральных сомнений, которые у вас могут быть по поводу порабощения превосходящего нас интеллекта, вас может беспокоить, что, возможно, суперинтеллект переиграет нас, уйдёт из-под контроля и одержит над нами верх. Но у меня есть коллеги, которые нормально относятся к победе ИИ, даже если это приведёт к исчезновению людей, до тех пор пока мы чувствуем, что ИИ — наследники, достойные нас, как наши дети. Но как мы узнаем, что ИИ принял наши главные ценности, и они не бессознательные зомби, которые только хотят казаться нам антропоморфными? Должны ли те люди, которые не хотят уничтожения человечества, также иметь право голоса? Итак, если вам не нравится ни один из высокотехнологичных вариантов, важно помнить, что устаревшие технологии — это самоубийство с глобальной точки зрения, так как, если мы не опережаем современные технологии, вопрос не в том, исчезнет ли человечество, будем ли мы просто уничтожены очередным убийцей-астероидом, супервулканом или другой проблемой, которая решалась бы с помощью технологий.
Итак, как насчёт того, чтобы получить всё и сразу с помощью СИИ, который не порабощён, но хорошо ведёт себя с нами, так как разделяет наши ценности? В этом смысл того, что Элиезер Юдковский назвал «дружественным ИИ», и если мы можем это сделать, было бы замечательно. Он мог бы не только устранить такие явления, как болезни и бедность, преступления и страдания, но и дал бы нам свободу выбора, исходя из нового фантастического разнообразия положительного опыта — по существу, делая нас хозяевами своей судьбы.
Подводя итоги, хочу сказать, что у нас сложная ситуация с технологиями, но общая картина достаточно проста. Большинство учёных ожидают создания СИИ в ближайшие десятилетия, и если к его появлению мы не будем подготовленными, это будет величайшей ошибкой в истории человечества — давайте это признаем. Это может сделать возможным жёсткую глобальную диктатуру с беспрецедентным неравенством, слежкой и страданиями, и, возможно, даже с исчезновением человечества. Но если мы будем разумно следовать нашему курсу, мы окажемся в фантастическом будущем, где каждому будет хорошо: бедные будут богаче, богатые будут богаче, каждый будет здоровым и будет жить так, как мечтает.
А теперь послушайте. Ребята, хотите ли вы политически правого или левого будущего? Жить в ханжеском обществе со строгими моральными правилами или в обществе «свободы для всех», как на фестивале Burning Man в режиме 24/7? Хотите ли прекрасные пляжи, леса и озёра, или предпочли бы с помощью компьютера переместить кое-какие атомы, сделав виртуальное реальным. С дружественным ИИ мы можем просто построить эти общества и дать людям свободу выбора того общества, где они хотят жить, потому что мы больше не будем ограничены своим интеллектом, а только законами физики. Поэтому ресурсы и пространство для этого будут астрономическими — в буквальном смысле слова.
Вот какой у нас выбор. Мы либо можем быть довольными своим будущим, принимая на веру то, что любая новая технология наверняка будет полезной, и повторять это снова и снова, как мантру, как будто мы плывём на корабле без руля к своему исчезновению. Либо мы можем быть целеустремлёнными, продумывая то, как управлять нашими технологиями и в каком направлении с ними двигаться, чтобы создать изумительную эпоху. Мы здесь для того, чтобы прославлять изумительную эпоху, и я чувствую, что его суть должна заключаться не в том, чтобы уступить технологиям, а чтобы с их помощью стать сильнее.
Спасибо.
(Аплодисменты)
TED.com translations are made possible by volunteer translators. Learn more about the Open Translation Project.
© TED Conferences, LLC. All rights reserved.